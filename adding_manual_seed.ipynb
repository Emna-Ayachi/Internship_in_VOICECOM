{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1719df-3e8f-4266-91ce-a696ab74cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rating                                             review\n",
      "0  negative  terrible place to work for i just heard a stor...\n",
      "1  negative   hours , minutes total time for an extremely s...\n",
      "2  negative  my less than stellar review is for service . w...\n",
      "3  negative  i m granting one star because there s no way t...\n",
      "4  negative  the food here is mediocre at best . i went aft...\n",
      "(56000, 2)\n",
      "Index(['rating', 'review'], dtype='object')\n",
      "rating    object\n",
      "review    object\n",
      "dtype: object\n",
      "          rating                                             review\n",
      "count      56000                                              56000\n",
      "unique         2                                              55993\n",
      "top     negative  i work a arrowhead in a smaller store so befor...\n",
      "freq       28000                                                  2\n",
      "rating    0\n",
      "review    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   rating  56000 non-null  object\n",
      " 1   review  56000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 875.1+ KB\n",
      "None\n",
      "     rating                                             review  label\n",
      "0  negative  terrible place to work for i just heard a stor...      0\n",
      "1  negative   hours , minutes total time for an extremely s...      0\n",
      "2  negative  my less than stellar review is for service . w...      0\n",
      "3  negative  i m granting one star because there s no way t...      0\n",
      "4  negative  the food here is mediocre at best . i went aft...      0\n",
      "m grant star s way n nas write door room open burly gentleman drill hammer drilling hammer check s go day evidently inn instal new lock system reason impossible wait check later today count solitude quiet d bring work s utterly impossible concentrate stay love lack concern respect set new low\n"
     ]
    }
   ],
   "source": [
    "#same code i used in Rating_Reviews_NN_PyTorch\n",
    "import pandas as pd\n",
    "file_path=r\"C:\\Users\\MSI\\OneDrive\\Desktop\\voicecom\\reviews.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())\n",
    "print(df.info())\n",
    "df[\"label\"] = df[\"rating\"].map({\"positive\": 1, \"negative\": 0})\n",
    "print(df.head())\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "def batch_spacy_lemmas(texts):\n",
    "    docs = nlp.pipe(texts, batch_size=100, n_process=-1) \n",
    "    for doc in docs:\n",
    "        lemmas = [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space and token.lemma_.isalpha()\n",
    "        ]\n",
    "        yield \" \".join(lemmas)\n",
    "df[\"lemmatized_review\"] = list(batch_spacy_lemmas(df[\"review\"]))\n",
    "print(df[\"lemmatized_review\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bef8b7-7ef8-4102-b4b7-a45e5ca32a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9df5801-70f1-475c-a3a1-33a7c5be71a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a4a3d5cc30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8050d0-1072-40e7-9007-3527af8031e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq=2, specials=[\"<pad>\", \"<unk>\"]):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(text.split())\n",
    "    words = [w for w, c in counter.items() if c >= min_freq]\n",
    "    itos = specials + words\n",
    "    stoi = {word: i for i, word in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "stoi, itos = build_vocab(df[\"lemmatized_review\"])\n",
    "\n",
    "def numericalize(text, stoi, max_len=100):\n",
    "    tokens = text.split()\n",
    "    ids = [stoi.get(t, stoi[\"<unk>\"]) for t in tokens[:max_len]]\n",
    "    ids += [stoi[\"<pad>\"]] * (max_len - len(ids))\n",
    "    return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "df[\"tensor_review\"] = df[\"lemmatized_review\"].apply(lambda x: numericalize(x, stoi, max_len=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aaeb99-7ab0-4364-8167-c31d5a4d4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  \n",
    "        pooled = embedded.mean(dim=1)  \n",
    "        return self.fc(pooled).squeeze(1)\n",
    "\n",
    "model = ReviewClassifier(vocab_size=len(stoi))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0da4cf7-f65b-43dc-a326-34e5f3504946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack(df[\"tensor_review\"].tolist())\n",
    "y = torch.tensor(df[\"label\"].values, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "train_ds, test_ds = random_split(dataset, [train_size, test_size], generator=g)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4059718-ebf9-43bb-a520-d6fa88d7b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "  Seed: 42\n",
      "  Embedding Dim: 64\n",
      "  Hidden Dim: 32\n",
      "  Learning Rate: 1e-3\n",
      "  Batch Size: 64\n",
      "  Max Length: 100\n",
      "  Vocab Size: 28460\n"
     ]
    }
   ],
   "source": [
    "accuracy_metric = BinaryAccuracy()\n",
    "precision_metric = BinaryPrecision()\n",
    "\n",
    "def run_epoch(model, loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    accuracy_metric.reset()\n",
    "    precision_metric.reset()\n",
    "\n",
    "    for texts, labels in loader:\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(texts)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).float()\n",
    "        labels = labels.float()\n",
    "\n",
    "        accuracy_metric.update(preds, labels)\n",
    "        precision_metric.update(preds, labels)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    prec = precision_metric.compute().item()\n",
    "\n",
    "    return avg_loss, acc, prec\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Seed: 42\")\n",
    "print(f\"  Embedding Dim: 64\")\n",
    "print(f\"  Hidden Dim: 32\")\n",
    "print(f\"  Learning Rate: 1e-3\")\n",
    "print(f\"  Batch Size: 64\")\n",
    "print(f\"  Max Length: 100\")\n",
    "print(f\"  Vocab Size: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd847b9d-d6f5-45f6-b282-4aa3707b92ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train  | Loss: 0.4634 | Acc: 0.7785 | Precision: 0.8198\n",
      "  Test   | Loss: 0.3146 | Acc: 0.8741 | Precision: 0.8733\n",
      "Epoch 2:\n",
      "  Train  | Loss: 0.2711 | Acc: 0.8964 | Precision: 0.8917\n",
      "  Test   | Loss: 0.2720 | Acc: 0.8913 | Precision: 0.8761\n",
      "Epoch 3:\n",
      "  Train  | Loss: 0.2220 | Acc: 0.9151 | Precision: 0.9101\n",
      "  Test   | Loss: 0.2587 | Acc: 0.8996 | Precision: 0.8951\n",
      "Epoch 4:\n",
      "  Train  | Loss: 0.1915 | Acc: 0.9275 | Precision: 0.9234\n",
      "  Test   | Loss: 0.2578 | Acc: 0.9007 | Precision: 0.9017\n",
      "Epoch 5:\n",
      "  Train  | Loss: 0.1684 | Acc: 0.9375 | Precision: 0.9343\n",
      "  Test   | Loss: 0.2633 | Acc: 0.9015 | Precision: 0.8966\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc, train_prec = run_epoch(model, train_loader, train=True)\n",
    "    test_loss, test_acc, test_prec = run_epoch(model, test_loader, train=False)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(f\"  Train  | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Precision: {train_prec:.4f}\")\n",
    "    print(f\"  Test   | Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | Precision: {test_prec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6944a82-5115-4421-9f40-5053f5f0695e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
