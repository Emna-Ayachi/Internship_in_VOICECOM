{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad229b-f783-4f26-b429-e488814d7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing the difference in lemmatization between SpaCy and Nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81477b6f-57b8-4125-8915-48d73de2186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The children are playing in the gardens.\",\n",
    "    \"He bettered his performance in the last match.\",\n",
    "    \"They saw the saw on the table.\",\n",
    "    \"Running is good for your health.\",\n",
    "    \"The mice were eating pieces of cheese.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223eb3e-7b87-41f2-9166-64a7663ca384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d04d7d-1071-4839-9d5a-0e1c4609d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def spacy_pipe(text):\n",
    "    doc = nlp(text)\n",
    "    return [{\"sentence\": sent.text,\n",
    "             \"tokens\": [t.text for t in sent],\n",
    "             \"lemmas\": [t.lemma_.lower() for t in sent\n",
    "                if not t.is_stop       \n",
    "                and not t.is_punct    \n",
    "                and not t.is_space    \n",
    "                and t.lemma_.isalpha()]}\n",
    "            for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3415eaf0-9764-485f-b9b0-d34ef86e4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— The children are playing in the gardens.\n",
      "spaCy: ['child', 'play', 'garden']\n",
      "\n",
      "— He bettered his performance in the last match.\n",
      "spaCy: ['better', 'performance', 'match']\n",
      "\n",
      "— They saw the saw on the table.\n",
      "spaCy: ['see', 'saw', 'table']\n",
      "\n",
      "— Running is good for your health.\n",
      "spaCy: ['run', 'good', 'health']\n",
      "\n",
      "— The mice were eating pieces of cheese.\n",
      "spaCy: ['mouse', 'eat', 'piece', 'cheese']\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    print(\"\\n—\", s)\n",
    "    all_lemmas = []\n",
    "    for sent in spacy_pipe(s):\n",
    "        all_lemmas.extend(sent[\"lemmas\"])\n",
    "    print(\"spaCy:\", all_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78154509-7d52-49e4-b0eb-6caff8247ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b1bfa1-defc-45f9-9573-16581685fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def to_wordnet_pos(tag):\n",
    "    return {\n",
    "        'J': wordnet.ADJ,\n",
    "        'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN,\n",
    "        'R': wordnet.ADV\n",
    "    }.get(tag[0], wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0c0067-60c5-4a37-9ed8-8ec6d9651d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLTK :\n",
      "['The', 'child', 'be', 'play', 'in', 'the', 'garden', '.']\n",
      "['He', 'better', 'his', 'performance', 'in', 'the', 'last', 'match', '.']\n",
      "['They', 'saw', 'the', 'saw', 'on', 'the', 'table', '.']\n",
      "['Running', 'be', 'good', 'for', 'your', 'health', '.']\n",
      "['The', 'mouse', 'be', 'eat', 'piece', 'of', 'cheese', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNLTK :\")\n",
    "for sent in sentences:\n",
    "    lemmas = [\n",
    "        lemmatizer.lemmatize(token, to_wordnet_pos(pos))\n",
    "        for token, pos in pos_tag(word_tokenize(sent))\n",
    "    ]\n",
    "    print(lemmas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
